{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0366536e-48a2-4122-bbc3-473a38c9facb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d228cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the database through pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82b2746f-084a-4000-b36f-03178f9a99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = pd.read_csv(\"tmdb_5000_movies.csv\")\n",
    "movie_credit = pd.read_csv(\"tmdb_5000_credits.csv\")\n",
    "\n",
    "# Merging both the dataset\n",
    "complete_data = movie_data.merge(movie_credit,on=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92bf850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data useful for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba79684-248b-4f64-8ca4-946e74cc2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_data = movie_data[['genres','id','keywords','overview']]\n",
    "# movie_credit = movie_credit[['cast','crew']]\n",
    "complete_data = complete_data[['genres','title','movie_id','keywords','overview','cast','crew']]\n",
    "# complete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42a7f074-0e14-4597-a842-00e8d69ca3cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genres      0\n",
       "title       0\n",
       "movie_id    0\n",
       "keywords    0\n",
       "overview    0\n",
       "cast        0\n",
       "crew        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping NA values \n",
    "complete_data.dropna(inplace=True)\n",
    "# Removing null entries\n",
    "complete_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ddc5d98-2dc8-472b-85a4-a404a8f6a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_data.iloc[0].genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc274e4e-76d3-4d3e-ac2f-14bdad821694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful modules and libraries\n",
    "\n",
    "import ast\n",
    "import sklearn\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed3e577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e9287f4-f7e7-459b-a291-215f89b06709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for converting the data into list as we cannot operate much with objects and pulling out\n",
    "# the important data and discarding which we dont need\n",
    "\n",
    "def convert(obj):\n",
    "    l = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        l.append(i['name'])\n",
    "    return l\n",
    "\n",
    "def convertcast(obj):\n",
    "    l = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        l.append(i['name'])\n",
    "        if(len(l) == 3):\n",
    "            break\n",
    "    return l\n",
    "\n",
    "def director(obj):\n",
    "    l = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if(i['job']=='Director'):\n",
    "            l.append(i['name'])\n",
    "    return l\n",
    "\n",
    "def remove_space(obj):\n",
    "    l=[]\n",
    "    for s in obj:\n",
    "        x=\"\".join(s.split(\" \"))\n",
    "        l.append(x)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e796ef45-88fc-4638-9fb6-e86c4405af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['genres']=complete_data['genres'].apply(convert)\n",
    "complete_data['keywords']=complete_data['keywords'].apply(convert)\n",
    "complete_data['cast']=complete_data['cast'].apply(convertcast)\n",
    "complete_data['crew']=complete_data['crew'].apply(director)\n",
    "complete_data['overview']=complete_data['overview'].apply(lambda x:x.split())\n",
    "\n",
    "# remove_space(complete_data['cast'])\n",
    "# complete_data['cast'] = complete_data['cast'].apply(remove_space)\n",
    "# complete_data['genres'] = complete_data['genres'].apply(remove_space)\n",
    "# complete_data['crew'] = complete_data['crew'].apply(remove_space)\n",
    "# complete_data['keywords'] = complete_data['keywords'].apply(remove_space)\n",
    "# Applying DRY Principle\n",
    "for types in ['cast', 'genres', 'crew', 'keywords']:\n",
    "    complete_data[types] = complete_data[types].apply(remove_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5ca994a-4336-44bc-bb73-28473109a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all to create a single column called tags.\n",
    "\n",
    "complete_data['tags']=complete_data['overview']+complete_data['genres']+complete_data['keywords']+complete_data['cast']+complete_data['crew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0688ebc5-ba8d-48ad-8d9e-f77ca660d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5babc8d8-c460-47f3-9ab3-87b357e41f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new dataframe\n",
    "\n",
    "new_df = complete_data[['movie_id','title','tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c2a2c41-642a-4d02-a8b5-4c3a61ad7c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anushtha bageria\\AppData\\Local\\Temp\\ipykernel_31256\\487797088.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags']=new_df['tags'].apply(lambda x:\" \".join(x))\n"
     ]
    }
   ],
   "source": [
    "new_df['tags']=new_df['tags'].apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c052f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e853ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing stemming\n",
    "\n",
    "def stem(text):\n",
    "    y=[]\n",
    "    \n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i))\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f460c032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anushtha bageria\\AppData\\Local\\Temp\\ipykernel_31256\\1429525103.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags']=new_df['tags'].apply(stem)\n",
      "C:\\Users\\anushtha bageria\\AppData\\Local\\Temp\\ipykernel_31256\\1429525103.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags']=new_df['tags'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "new_df['tags']=new_df['tags'].apply(stem)\n",
    "new_df['tags']=new_df['tags'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f6e330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words algo using library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aef0e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# cv = CountVectorizer(max_features=5000,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8641f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=cv.fit_transform(new_df['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d90a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words algo without using library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5431abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2count= {}\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "763d9a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vectorization(sentence):\n",
    "#     words = nltk.word_tokenize(sentence)\n",
    "#     for word in words:\n",
    "#         if word not in word2count.keys():\n",
    "#             word2count[word] = 1\n",
    "#         else:\n",
    "#             word2count[word] += 1\n",
    "\n",
    "# for data in new_df['tags']:\n",
    "#     words = nltk.word_tokenize(data)\n",
    "#     filtered_sentence = [w for w in words if not w.lower() in stop_words]\n",
    "#     for word in filtered_sentence:\n",
    "#         if word not in word2count.keys():\n",
    "#             word2count[word] = 1\n",
    "#         else:\n",
    "#             word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2feaec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df['tags'].apply(vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b01be1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(word2count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "489782c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import heapq\n",
    "# freq_words = heapq.nlargest(100, word2count, key=word2count.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66edd665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = []\n",
    "# for data in new_df['tags']:\n",
    "#     vector = []\n",
    "#     for word in freq_words:\n",
    "#         if word in nltk.word_tokenize(data):\n",
    "#             vector.append(1)\n",
    "#         else:\n",
    "#             vector.append(0)\n",
    "#     X.append(vector)\n",
    "# X = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76a81801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7730caec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tf-idf for vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a72cc1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagOfWords = []\n",
    "# for i in new_df['tags']:\n",
    "#     bagOfWords.append(i.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf327964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniqueWords = set()\n",
    "# wordsList = []\n",
    "# for i in new_df['tags']:\n",
    "#     for word in i.split(' '):\n",
    "#         wordsList.append(word)\n",
    "# uniqueWords = set(wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d33229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2Count = []\n",
    "# for data in new_df['tags']:\n",
    "#     wordsDict = dict.fromkeys(uniqueWords, 0)\n",
    "#     for word in data.split(' '):\n",
    "#         wordsDict[word]+=1\n",
    "#     word2Count.append(wordsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35aea28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def computeTF(wordDict, bagOfWordsList):\n",
    "#     tfDict = {}\n",
    "#     bagOfWordsCount = len(bagOfWordsList)\n",
    "#     for word, count in wordDict.items():\n",
    "#         tfDict[word] = count / float(bagOfWordsCount)\n",
    "#     return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df6b623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfList = []\n",
    "# j = 0\n",
    "# for i in new_df['tags']:\n",
    "#     tfList.append(computeTF(word2Count[j], i.split(' ')))\n",
    "#     j += 1\n",
    "# print(tfList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ba84374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF = Term Frequency (TF) * Inverse Document Frequency (IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6b048de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facing memory error so applying tf-idf using the libraries itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c362a706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in new_df['tags']:\n",
    "    data.append(i)\n",
    "result = tfidf.fit_transform(data)\n",
    "\n",
    "resultMatrix = result.toarray()\n",
    "print(resultMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24d8f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ele1, ele2 in zip(tfidf.get_feature_names(), tfidf.idf_):\n",
    "#     print(ele1, ':', ele2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe1d2e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using cosine similarity for finding the nearest similar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4d4e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(resultMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a64c5b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie):\n",
    "    index = new_df[new_df['title'] == movie].index[0]\n",
    "    distances = sorted(list(enumerate(similarity[index])),reverse=True,key = lambda x: x[1])\n",
    "    \n",
    "    for i in distances[1:11]:\n",
    "        print(new_df.iloc[i[0]].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d055c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aliens\n",
      "Falcon Rising\n",
      "Battle: Los Angeles\n",
      "Apollo 18\n",
      "Aliens vs Predator: Requiem\n",
      "Meet Dave\n",
      "Titan A.E.\n",
      "Star Trek Into Darkness\n",
      "The Book of Life\n",
      "Predators\n"
     ]
    }
   ],
   "source": [
    "recommend('Avatar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3dbfaaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de8ab12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(new_df.to_dict(),open('D:/movie recommendation system/recommendation system code/movies_dict.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d9cca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(similarity,open('D:/movie recommendation system/recommendation system code/similarity.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf9ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
